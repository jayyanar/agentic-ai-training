{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i5GiWdqQDgH"
      },
      "source": [
        "### LCEL Deepdive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-groq langchain_community langchain_huggingface faiss-cpu"
      ],
      "metadata": {
        "id": "DPDhk2lxQWtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDCje1SHQDgI"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "#from dotenv import load_dotenv\n",
        "#load_dotenv()\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CplBwP7dQDgI"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"Explain about {topic} in detail\")\n",
        "#model = ChatOpenAI()\n",
        "# Initialize the Groq model\n",
        "model = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        ")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"topic\": \"ice cream\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYsPkRcuQDgJ"
      },
      "outputs": [],
      "source": [
        "print(prompt.invoke({\"topic\": \"ice cream\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IypsvO3oQDgJ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages.human import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content='tell me a short joke about ice cream')]\n",
        "model.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHpjNf7WQDgJ"
      },
      "source": [
        "### What is this \"|\" in Python?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGht2RsIQDgJ"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class CRunnable(ABC):\n",
        "    def __init__(self):\n",
        "        self.next = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def process(self, data):\n",
        "        \"\"\"\n",
        "        This method must be implemented by subclasses to define\n",
        "        data processing behavior.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def invoke(self, data):\n",
        "        processed_data = self.process(data)\n",
        "        if self.next is not None:\n",
        "            return self.next.invoke(processed_data)\n",
        "        return processed_data\n",
        "\n",
        "    def __or__(self, other):\n",
        "        return CRunnableSequence(self, other)\n",
        "\n",
        "class CRunnableSequence(CRunnable):\n",
        "    def __init__(self, first, second):\n",
        "        super().__init__()\n",
        "        self.first = first\n",
        "        self.second = second\n",
        "\n",
        "    def process(self, data):\n",
        "        return data\n",
        "\n",
        "    def invoke(self, data):\n",
        "        first_result = self.first.invoke(data)\n",
        "        return self.second.invoke(first_result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyVu3RAEQDgJ"
      },
      "outputs": [],
      "source": [
        "class AddTen(CRunnable):\n",
        "    def process(self, data):\n",
        "        print(\"AddTen: \", data)\n",
        "        return data + 10\n",
        "\n",
        "class MultiplyByTwo(CRunnable):\n",
        "    def process(self, data):\n",
        "        print(\"Multiply by 2: \", data)\n",
        "        return data * 2\n",
        "\n",
        "class ConvertToString(CRunnable):\n",
        "    def process(self, data):\n",
        "        print(\"Convert to string: \", data)\n",
        "        return f\"Result: {data}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N1o2mcNQDgK"
      },
      "outputs": [],
      "source": [
        "a = AddTen()\n",
        "b = MultiplyByTwo()\n",
        "c = ConvertToString()\n",
        "\n",
        "chain = a | b | c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJv5G-x2QDgK"
      },
      "outputs": [],
      "source": [
        "result = chain.invoke(10)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9k_RxZCQDgK"
      },
      "source": [
        "### Runnables from LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCfNvqMRQDgK"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8dxYbUGQDgK"
      },
      "outputs": [],
      "source": [
        "chain = RunnablePassthrough() | RunnablePassthrough () | RunnablePassthrough ()\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sqHfgWqQDgK"
      },
      "outputs": [],
      "source": [
        "def input_to_upper(input: str):\n",
        "    output = input.upper()\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJPXmLEnQDgK"
      },
      "outputs": [],
      "source": [
        "chain = RunnablePassthrough() | RunnableLambda(input_to_upper) | RunnablePassthrough()\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgL28CSVQDgK"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": RunnablePassthrough()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j0pcnA6QDgL"
      },
      "outputs": [],
      "source": [
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoRPPQALQDgL"
      },
      "outputs": [],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrqZ_nrqQDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": lambda z: z[\"input2\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rxIIM9PQDgL"
      },
      "outputs": [],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMlOLFWCQDgL"
      },
      "source": [
        "### Nested chains - now it gets more complicated!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_rqdmT2QDgL"
      },
      "outputs": [],
      "source": [
        "def find_keys_to_uppercase(input: dict):\n",
        "    output = input.get(\"input\", \"not found\").upper()\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4JEpMo_QDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough() | RunnableLambda(find_keys_to_uppercase), \"y\": lambda z: z[\"input2\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LdbNEBIQDgL"
      },
      "outputs": [],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vegnFMbmQDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough()})\n",
        "\n",
        "def assign_func(input):\n",
        "    return 100\n",
        "\n",
        "def multiply(input):\n",
        "    return input * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxO4LKE-QDgL"
      },
      "outputs": [],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUOJalpIQDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough()}).assign(extra=RunnableLambda(assign_func))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJn6KsmuQDgL"
      },
      "outputs": [],
      "source": [
        "result = chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euzpl0q_QDgM"
      },
      "source": [
        "### Combine multiple chains (incl. coercion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLj8ph1dQDgM"
      },
      "outputs": [],
      "source": [
        "def extractor(input: dict):\n",
        "    return input.get(\"extra\", \"Key not found\")\n",
        "\n",
        "def cupper(upper: str):\n",
        "    return str(upper).upper()\n",
        "\n",
        "new_chain = RunnableLambda(extractor) | RunnableLambda(cupper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmZ_HmW5QDgM"
      },
      "outputs": [],
      "source": [
        "new_chain.invoke({\"extra\": \"test\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EANjuTDQDgM"
      },
      "outputs": [],
      "source": [
        "final_chain = chain | new_chain\n",
        "final_chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2YB8IXNQDgM"
      },
      "source": [
        "### Real Work example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLPYCzJyQDgM"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "#from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.from_texts(\n",
        "    [\"Cats love thuna\"], embedding=embeddings\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template=template)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    RunnableParallel({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()})\n",
        "    | prompt\n",
        "    | ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0, max_retries=2)\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBaX_HG7QDgM"
      },
      "outputs": [],
      "source": [
        "rag_chain.invoke(\"What do cats like to eat?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdHywXy7QDgM"
      },
      "outputs": [],
      "source": [
        "RunnableParallel({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}).invoke(\"What do cats like to eat?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiQmvzNpQDgM"
      },
      "outputs": [],
      "source": [
        "prompt.invoke({\"context\": \"Cats love thuna\", \"question\": \"What do cats like to eat?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht2rISCuQDgM"
      },
      "outputs": [],
      "source": [
        "model.invoke(prompt.invoke({\"context\": \"Cats love thuna\", \"question\": \"What do cats like to eat?\"}))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-crash-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}