{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i5GiWdqQDgH"
      },
      "source": [
        "### LCEL Deepdive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-groq langchain_community langchain_huggingface faiss-cpu"
      ],
      "metadata": {
        "id": "DPDhk2lxQWtV"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "oDCje1SHQDgI"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "#from dotenv import load_dotenv\n",
        "#load_dotenv()\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "CplBwP7dQDgI",
        "outputId": "caaadb0a-6969-4a56-e09c-f380ed4c464b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ice cream is a frozen dessert made from a mixture of cream, sugar, and flavorings, typically frozen to a smooth and creamy consistency. It has been a popular treat for centuries, with its origins dating back to ancient civilizations in the Middle East and China.\\n\\n**History of Ice Cream**\\n\\nThe earliest known evidence of ice cream-like desserts dates back to ancient Mesopotamia, around 2000 BC. The ancient Greeks and Romans also enjoyed frozen desserts made from snow and sweetened with honey. However, the modern version of ice cream as we know it today originated in Italy in the 16th century.\\n\\nThe Medici family in Florence, Italy, commissioned a chef named Bernardo Buontalenti to create a frozen dessert for a banquet. Buontalenti created a frozen mixture of cream, sugar, and fruit, which became known as \"gelato.\" The name \"gelato\" is still used today to describe Italian-style ice cream.\\n\\n**Ingredients of Ice Cream**\\n\\nIce cream is typically made from a combination of the following ingredients:\\n\\n1. **Cream**: Heavy cream, whole milk, or a combination of both are used to give ice cream its rich and creamy texture.\\n2. **Sugar**: Granulated sugar is added to balance out the flavor and provide sweetness.\\n3. **Flavorings**: Vanilla, chocolate, nuts, fruit, and other flavorings are added to give ice cream its unique taste and aroma.\\n4. **Stabilizers**: Stabilizers such as guar gum, carrageenan, and xanthan gum are added to prevent ice crystals from forming and to give ice cream a smooth texture.\\n5. **Emulsifiers**: Emulsifiers such as mono- and diglycerides are added to help mix oil and water-based ingredients together.\\n\\n**Types of Ice Cream**\\n\\nThere are several types of ice cream, including:\\n\\n1. **Gelato**: Italian-style ice cream that is denser and creamier than traditional ice cream.\\n2. **Sorbet**: A frozen dessert made from fruit puree and sugar, without any dairy products.\\n3. **Frozen Yogurt**: A frozen dessert made from yogurt and sugar, with a tangy flavor.\\n4. **Soft-Serve Ice Cream**: A type of ice cream that is dispensed from a machine and has a soft and airy texture.\\n5. **Artisanal Ice Cream**: Handcrafted ice cream made from high-quality ingredients and unique flavor combinations.\\n\\n**Manufacturing Process of Ice Cream**\\n\\nThe manufacturing process of ice cream involves the following steps:\\n\\n1. **Mixing**: The ingredients are mixed together in a large tank to create a uniform mixture.\\n2. **Pasteurization**: The mixture is heated to a high temperature to kill off any bacteria and extend the shelf life.\\n3. **Homogenization**: The mixture is forced through a small opening to break down the fat molecules and create a smooth texture.\\n4. **Aging**: The mixture is left to age in a cold storage room to allow the flavors to mature and the texture to thicken.\\n5. **Freezing**: The mixture is frozen to a temperature of around -20Â°C to create a smooth and creamy texture.\\n6. **Packaging**: The ice cream is packaged in containers or cones and shipped to stores.\\n\\n**Nutritional Information of Ice Cream**\\n\\nIce cream is a high-calorie food that is rich in sugar, fat, and calories. A typical serving of ice cream contains:\\n\\n* Calories: 200-300 per serving\\n* Fat: 10-15 grams per serving\\n* Sugar: 20-30 grams per serving\\n* Sodium: 50-100 milligrams per serving\\n\\n**Health Benefits of Ice Cream**\\n\\nWhile ice cream is a treat that should be consumed in moderation, it does have some health benefits. Ice cream contains:\\n\\n* **Protein**: Ice cream is a good source of protein, which is essential for muscle growth and repair.\\n* **Calcium**: Ice cream is a good source of calcium, which is essential for bone health.\\n* **Vitamins and Minerals**: Ice cream contains vitamins and minerals such as vitamin D, vitamin B12, and potassium.\\n\\n**Fun Facts about Ice Cream**\\n\\n1. **The world\\'s largest ice cream sundae** was made in Wisconsin, USA, in 1988 and weighed over 5,000 pounds.\\n2. **The first ice cream cone** was invented by Charles Menches, an ice cream vendor at the 1904 World\\'s Fair in St. Louis, Missouri.\\n3. **The most expensive ice cream** in the world is made from gold and costs over $1,000 per scoop.\\n4. **The world\\'s largest ice cream factory** is located in Italy and produces over 1 million liters of ice cream per day.\\n5. **The first ice cream truck** was invented by Italo Marchioni, an Italian immigrant to the United States, in the early 20th century.\\n\\nIn conclusion, ice cream is a delicious and popular treat that has been enjoyed for centuries. With its rich history, unique ingredients, and various types, ice cream is a treat that is sure to bring joy to people of all ages.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"Explain about {topic} in detail\")\n",
        "#model = ChatOpenAI()\n",
        "# Initialize the Groq model\n",
        "model = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        ")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"topic\": \"ice cream\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "iYsPkRcuQDgJ",
        "outputId": "14ae66dd-e066-428d-de85-00e7ebb24b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[HumanMessage(content='Explain about ice cream in detail', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "print(prompt.invoke({\"topic\": \"ice cream\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "IypsvO3oQDgJ",
        "outputId": "866e0515-1038-4ac7-81a2-9b8a1a3a3677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Why did the ice cream go to the doctor? \\n\\nBecause it had a meltdown.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 43, 'total_tokens': 61, 'completion_time': 0.026576425, 'completion_tokens_details': None, 'prompt_time': 0.00279619, 'prompt_tokens_details': None, 'queue_time': 0.005851801, 'total_time': 0.029372615}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9ca2574dca', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb348-5e5a-7c23-ae2c-c2cb29772967-0', usage_metadata={'input_tokens': 43, 'output_tokens': 18, 'total_tokens': 61})"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "from langchain_core.messages.human import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content='tell me a short joke about ice cream')]\n",
        "model.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHpjNf7WQDgJ"
      },
      "source": [
        "### What is this \"|\" in Python?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "PGht2RsIQDgJ"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class CRunnable(ABC):\n",
        "    def __init__(self):\n",
        "        self.next = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def process(self, data):\n",
        "        \"\"\"\n",
        "        This method must be implemented by subclasses to define\n",
        "        data processing behavior.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def invoke(self, data):\n",
        "        processed_data = self.process(data)\n",
        "        if self.next is not None:\n",
        "            return self.next.invoke(processed_data)\n",
        "        return processed_data\n",
        "\n",
        "    def __or__(self, other):\n",
        "        return CRunnableSequence(self, other)\n",
        "\n",
        "class CRunnableSequence(CRunnable):\n",
        "    def __init__(self, first, second):\n",
        "        super().__init__()\n",
        "        self.first = first\n",
        "        self.second = second\n",
        "\n",
        "    def process(self, data):\n",
        "        return data\n",
        "\n",
        "    def invoke(self, data):\n",
        "        first_result = self.first.invoke(data)\n",
        "        return self.second.invoke(first_result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "KyVu3RAEQDgJ"
      },
      "outputs": [],
      "source": [
        "class AddTen(CRunnable):\n",
        "    def process(self, data):\n",
        "        print(\"AddTen: \", data)\n",
        "        return data + 10\n",
        "\n",
        "class MultiplyByTwo(CRunnable):\n",
        "    def process(self, data):\n",
        "        print(\"Multiply by 2: \", data)\n",
        "        return data * 2\n",
        "\n",
        "class ConvertToString(CRunnable):\n",
        "    def process(self, data):\n",
        "        print(\"Convert to string: \", data)\n",
        "        return f\"Result: {data}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "9N1o2mcNQDgK"
      },
      "outputs": [],
      "source": [
        "a = AddTen()\n",
        "b = MultiplyByTwo()\n",
        "c = ConvertToString()\n",
        "\n",
        "chain = a | b | c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "iJv5G-x2QDgK",
        "outputId": "b50a1727-600b-4aa7-ba7b-50d353dde654",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AddTen:  10\n",
            "Multiply by 2:  20\n",
            "Convert to string:  40\n",
            "Result: 40\n"
          ]
        }
      ],
      "source": [
        "result = chain.invoke(10)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9k_RxZCQDgK"
      },
      "source": [
        "### Runnables from LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "QCfNvqMRQDgK"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "z8dxYbUGQDgK",
        "outputId": "f8252ce8-a84a-4a97-fdc9-287644635654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "chain = RunnablePassthrough() | RunnablePassthrough () | RunnablePassthrough ()\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "_sqHfgWqQDgK"
      },
      "outputs": [],
      "source": [
        "def input_to_upper(input: str):\n",
        "    output = input.upper()\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "WJPXmLEnQDgK",
        "outputId": "b491ef46-830b-4769-dc1d-08f7e65dbb8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HELLO'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "chain = RunnablePassthrough() | RunnableLambda(input_to_upper) | RunnablePassthrough()\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "JgL28CSVQDgK"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": RunnablePassthrough()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "0j0pcnA6QDgL",
        "outputId": "673a5a22-bb3d-43be-a6fe-035881993310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 'hello', 'y': 'hello'}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "uoRPPQALQDgL",
        "outputId": "975b245d-afb6-45ea-b58c-2639fed6c354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': {'input': 'hello', 'input2': 'goodbye'},\n",
              " 'y': {'input': 'hello', 'input2': 'goodbye'}}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "vrqZ_nrqQDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough(), \"y\": lambda z: z[\"input2\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "0rxIIM9PQDgL",
        "outputId": "b63525f1-8409-44db-f59a-3036f645d3ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': {'input': 'hello', 'input2': 'goodbye'}, 'y': 'goodbye'}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMlOLFWCQDgL"
      },
      "source": [
        "### Nested chains - now it gets more complicated!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "G_rqdmT2QDgL"
      },
      "outputs": [],
      "source": [
        "def find_keys_to_uppercase(input: dict):\n",
        "    output = input.get(\"input\", \"not found\").upper()\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "a4JEpMo_QDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough() | RunnableLambda(find_keys_to_uppercase), \"y\": lambda z: z[\"input2\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "-LdbNEBIQDgL",
        "outputId": "079cd8a0-f6f2-47df-e1f7-ad51ca3c200a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 'HELLO', 'y': 'goodbye'}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "vegnFMbmQDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough()})\n",
        "\n",
        "def assign_func(input):\n",
        "    return 100\n",
        "\n",
        "def multiply(input):\n",
        "    return input * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "lxO4LKE-QDgL",
        "outputId": "3341aeb6-e7c6-4a33-8edb-a8074341e6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': {'input': 'hello', 'input2': 'goodbye'}}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "aUOJalpIQDgL"
      },
      "outputs": [],
      "source": [
        "chain = RunnableParallel({\"x\": RunnablePassthrough()}).assign(extra=RunnableLambda(assign_func))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "fJn6KsmuQDgL",
        "outputId": "8993b985-6d77-492a-e966-7f23c06ff130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': {'input': 'hello', 'input2': 'goodbye'}, 'extra': 100}\n"
          ]
        }
      ],
      "source": [
        "result = chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euzpl0q_QDgM"
      },
      "source": [
        "### Combine multiple chains (incl. coercion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "CLj8ph1dQDgM"
      },
      "outputs": [],
      "source": [
        "def extractor(input: dict):\n",
        "    return input.get(\"extra\", \"Key not found\")\n",
        "\n",
        "def cupper(upper: str):\n",
        "    return str(upper).upper()\n",
        "\n",
        "new_chain = RunnableLambda(extractor) | RunnableLambda(cupper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "CmZ_HmW5QDgM",
        "outputId": "8cd7f75f-a174-47fa-9aad-f1d101a0e562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TEST'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "new_chain.invoke({\"extra\": \"test\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "8EANjuTDQDgM",
        "outputId": "6dd010d0-3684-473a-e3dd-947ee47e81b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'100'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "final_chain = chain | new_chain\n",
        "final_chain.invoke({\"input\": \"hello\", \"input2\": \"goodbye\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2YB8IXNQDgM"
      },
      "source": [
        "### Real Work example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "fLPYCzJyQDgM"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "#from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectorstore = FAISS.from_texts(\n",
        "    [\"Cats love thuna\"], embedding=embeddings\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template=template)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    RunnableParallel({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()})\n",
        "    | prompt\n",
        "    | ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0, max_retries=2)\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "YBaX_HG7QDgM",
        "outputId": "7a380107-a51a-4b89-adf7-17cc607f0dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cats love thuna.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "rag_chain.invoke(\"What do cats like to eat?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "YdHywXy7QDgM",
        "outputId": "7aa3081f-74d2-42fe-85ac-231ddc4ad1c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'Cats love thuna', 'question': 'What do cats like to eat?'}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "RunnableParallel({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}).invoke(\"What do cats like to eat?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "jiQmvzNpQDgM",
        "outputId": "0297f79c-e426-4551-8c5c-5f530269c8d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='Answer the question based only on the following context:\\nCats love thuna\\n\\nQuestion: What do cats like to eat?\\n', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "prompt.invoke({\"context\": \"Cats love thuna\", \"question\": \"What do cats like to eat?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ht2rISCuQDgM",
        "outputId": "12eb1c85-41ea-4aea-ca4e-e41e04d4e8ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Cats love thuna.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 60, 'total_tokens': 67, 'completion_time': 0.019370566, 'completion_tokens_details': None, 'prompt_time': 0.006269436, 'prompt_tokens_details': None, 'queue_time': 0.070878072, 'total_time': 0.025640002}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_6b5c123dd9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bb348-64fa-7361-b328-baab32631d3c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 7, 'total_tokens': 67})"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "model.invoke(prompt.invoke({\"context\": \"Cats love thuna\", \"question\": \"What do cats like to eat?\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "245jLDh3QDgM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "J98FEf8tQDgN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-crash-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}