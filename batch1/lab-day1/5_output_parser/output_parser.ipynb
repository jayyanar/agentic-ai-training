{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77183a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71424e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and manipulate human language. They are built using deep learning techniques, particularly neural networks with billions of parameters, enabling them to process vast amounts of text data. LLMs, like OpenAI's GPT series, are trained on diverse datasets, allowing them to perform a wide range of language tasks, including translation, summarization, and conversation. Their ability to generate coherent and contextually relevant text makes them valuable for applications in customer service, content creation, and more. However, they also raise ethical concerns regarding bias, misinformation, and privacy.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 126, 'prompt_tokens': 17, 'total_tokens': 143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CNxGhLQ6f4Yoyeb7EqxVcZFYKF2XF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--dbe38967-6073-486a-93db-97efb9540c99-0' usage_metadata={'input_tokens': 17, 'output_tokens': 126, 'total_tokens': 143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")\n",
    "prompt = PromptTemplate(\n",
    "        template=\"Explain about {topic} in 100 words.\",\n",
    "        input_variables=[\"topic\"]\n",
    "    )\n",
    "\n",
    "chain_without_parser = prompt | model\n",
    "result_without = chain_without_parser.invoke({\"topic\": \"Large Language Models\"})\n",
    "print(result_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102ed1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) are advanced artificial intelligence systems designed to understand, generate, and manipulate human language. They are built using deep learning techniques, particularly neural networks with billions of parameters, trained on vast datasets comprising text from the internet, books, and other sources. LLMs, like OpenAI's GPT series, excel in tasks such as translation, summarization, and conversation by predicting the next word in a sentence. Their ability to generate coherent and contextually relevant text makes them valuable for applications in customer service, content creation, and more, although they also raise ethical concerns regarding bias and misinformation.\n"
     ]
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "chain_with_parser = prompt | model | parser\n",
    "result_with = chain_with_parser.invoke({\"topic\": \"Large Language Models\"})\n",
    "print(result_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57f0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_without_parser = PromptTemplate(\n",
    "        template=\"Analyze the movie {movie_title} and provide details about genre, rating, and key themes.\",\n",
    "        input_variables=[\"movie_title\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d33636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\"The Matrix,\" released in 1999 and directed by the Wachowskis, is a groundbreaking film that blends several genres, including science fiction, action, and cyberpunk. It is renowned for its innovative special effects, particularly the use of \"bullet time,\" and its philosophical depth.\\n\\n### Genre:\\n- **Science Fiction**: The film explores futuristic concepts such as artificial intelligence, virtual reality, and dystopian futures.\\n- **Action**: Known for its intense and stylized action sequences, including martial arts and gunfights.\\n- **Cyberpunk**: Features a high-tech, low-life aesthetic typical of the cyberpunk genre, with themes of rebellion against oppressive systems.\\n\\n### Rating:\\n- **MPAA Rating**: R (Restricted) for sci-fi violence and brief language.\\n- **Critical Reception**: \"The Matrix\" received widespread critical acclaim for its innovative visual effects, action sequences, and thought-provoking narrative. It holds a high rating on review aggregator sites like Rotten Tomatoes and Metacritic.\\n\\n### Key Themes:\\n1. **Reality vs. Illusion**: The film questions the nature of reality, exploring the idea that the world perceived by humans might be a simulated reality created by machines.\\n2. **Control and Freedom**: It delves into themes of control, with the Matrix serving as a metaphor for societal structures that limit human freedom, and the quest for liberation.\\n3. **Identity and Self-Discovery**: The protagonist, Neo, undergoes a journey of self-discovery, learning about his true identity and potential.\\n4. **Technology and Humanity**: The film examines the relationship between humans and technology, particularly the potential for technology to dominate and dehumanize.\\n5. **Philosophical and Religious Allegories**: It incorporates elements from various philosophical and religious traditions, including existentialism, Buddhism, and Christianity, to explore deeper questions about existence and purpose.\\n\\n\"The Matrix\" has had a lasting impact on both popular culture and the film industry, influencing countless other works and sparking discussions about technology, reality, and human nature.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 417, 'prompt_tokens': 24, 'total_tokens': 441, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CNxJe7DE2Og4PTruMJKnUmHJDmd0D', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--4182e76f-2eb9-4d98-8b2b-9cf9d82865e3-0' usage_metadata={'input_tokens': 24, 'output_tokens': 417, 'total_tokens': 441, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain_without_parser = prompt_without_parser | model\n",
    "result_without = chain_without_parser.invoke({\"movie_title\": \"The Matrix\"})\n",
    "print(result_without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c881b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fa01d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'The Matrix', 'genre': ['Science Fiction', 'Action', 'Adventure'], 'rating': 'R', 'key_themes': ['Reality vs. Illusion', 'Control and Freedom', 'Technology and Humanity', 'Identity and Self-discovery', 'Rebellion and Resistance']}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "prompt_with_parser = PromptTemplate(\n",
    "    template=\"\"\"Analyze the movie {movie_title} and provide details about genre, rating, and key themes.\n",
    "    {format_instructions}\"\"\",\n",
    "    input_variables=[\"movie_title\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    "    )\n",
    "    \n",
    "chain_with_parser = prompt_with_parser | model | parser\n",
    "result_with = chain_with_parser.invoke({\"movie_title\": \"The Matrix\"})\n",
    "print(result_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e625a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb92398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic model\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Person's full name\")\n",
    "    age: int = Field(description=\"Person's age in years\", ge=0, le=150)\n",
    "    occupation: str = Field(description=\"Person's job or profession\")\n",
    "    skills: List[str] = Field(description=\"List of person's key skills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f13cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE PARSER:\n",
      "Prompt used: text='Create a fictional person profile for a data scientist.'\n",
      "Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "result_without: content='**Name:** Dr. Alex Chen\\n\\n**Age:** 34\\n\\n**Location:** San Francisco, California, USA\\n\\n**Education:**\\n- Ph.D. in Computer Science, specializing in Machine Learning, Stanford University\\n- M.S. in Statistics, University of California, Berkeley\\n- B.S. in Mathematics and Computer Science, University of Illinois at Urbana-Champaign\\n\\n**Professional Experience:**\\n\\n1. **Senior Data Scientist at TechNova Solutions (2020 - Present)**\\n   - Lead a team of data scientists in developing predictive models for client projects across various industries, including healthcare, finance, and e-commerce.\\n   - Implemented a machine learning algorithm that increased client sales forecasting accuracy by 25%.\\n   - Spearheaded the development of an internal tool that automates data cleaning processes, reducing project setup time by 40%.\\n\\n2. **Data Scientist at InnovateAI (2016 - 2020)**\\n   - Developed and deployed machine learning models for natural language processing applications, improving sentiment analysis accuracy by 30%.\\n   - Collaborated with cross-functional teams to integrate AI solutions into existing products, enhancing user experience and engagement.\\n   - Conducted workshops and training sessions to upskill team members in advanced data science techniques.\\n\\n3. **Data Analyst at GreenTech Analytics (2013 - 2016)**\\n   - Analyzed large datasets to identify trends and insights for renewable energy projects.\\n   - Created interactive dashboards and visualizations to communicate findings to stakeholders.\\n   - Contributed to a project that optimized energy consumption predictions, leading to a 15% reduction in operational costs.\\n\\n**Skills:**\\n- Programming Languages: Python, R, SQL, Java\\n- Machine Learning Frameworks: TensorFlow, PyTorch, Scikit-learn\\n- Data Visualization Tools: Tableau, Power BI, Matplotlib\\n- Big Data Technologies: Hadoop, Spark\\n- Cloud Platforms: AWS, Google Cloud Platform\\n- Natural Language Processing, Deep Learning, Predictive Analytics\\n\\n**Certifications:**\\n- Certified Data Scientist (CDS) by the Data Science Council of America\\n- AWS Certified Machine Learning â€“ Specialty\\n\\n**Publications:**\\n- \"Advancements in Neural Network Architectures for Natural Language Processing,\" Journal of Machine Learning Research, 2021.\\n- \"A Comprehensive Guide to Predictive Analytics in E-commerce,\" Data Science Review, 2019.\\n\\n**Professional Affiliations:**\\n- Member of the Association for Computing Machinery (ACM)\\n- Member of the Institute of Electrical and Electronics Engineers (IEEE)\\n\\n**Personal Interests:**\\n- Passionate about environmental sustainability and volunteers with local green initiatives.\\n- Enjoys hiking and photography, often combining the two to capture landscapes.\\n- Avid reader of science fiction and enjoys exploring the intersection of technology and society.\\n\\n**Contact Information:**\\n- Email: alex.chen@datainsights.com\\n- LinkedIn: linkedin.com/in/alexchen-datascience\\n\\nDr. Alex Chen is a highly skilled and experienced data scientist with a strong academic background and a proven track record of delivering impactful data-driven solutions. With a passion for innovation and a commitment to continuous learning, Alex is dedicated to advancing the field of data science and applying it to solve real-world challenges.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 649, 'prompt_tokens': 17, 'total_tokens': 666, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CNxONOFpJ2QDun9UM2R7R9qfWNr8I', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a445b660-a774-447c-a446-daeeae5ed332-0' usage_metadata={'input_tokens': 17, 'output_tokens': 649, 'total_tokens': 666, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "AFTER PARSER:\n",
      "Prompt used: text='Create a fictional person profile for a data scientist.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"Person\\'s full name\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"Person\\'s age in years\", \"maximum\": 150, \"minimum\": 0, \"title\": \"Age\", \"type\": \"integer\"}, \"occupation\": {\"description\": \"Person\\'s job or profession\", \"title\": \"Occupation\", \"type\": \"string\"}, \"skills\": {\"description\": \"List of person\\'s key skills\", \"items\": {\"type\": \"string\"}, \"title\": \"Skills\", \"type\": \"array\"}}, \"required\": [\"name\", \"age\", \"occupation\", \"skills\"]}\\n```'\n",
      "Type: <class '__main__.Person'>\n",
      "result_with: name='Alexandra Chen' age=34 occupation='Data Scientist' skills=['Python', 'Machine Learning', 'Data Visualization', 'Statistical Analysis', 'SQL', 'Big Data Technologies', 'Deep Learning', 'R Programming']\n"
     ]
    }
   ],
   "source": [
    "prompt_without_parser = PromptTemplate(\n",
    "    template=\"Create a fictional person profile for a {profession}.\",\n",
    "    input_variables=[\"profession\"]\n",
    ")\n",
    "\n",
    "chain_without_parser = prompt_without_parser | model\n",
    "result_without = chain_without_parser.invoke({\"profession\": \"data scientist\"})\n",
    "\n",
    "print(\"BEFORE PARSER:\")\n",
    "print(\"Prompt used:\", prompt_without_parser.invoke({\"profession\": \"data scientist\"}))\n",
    "print(f\"Type: {type(result_without)}\")\n",
    "print(f\"result_without: {result_without}\")\n",
    "print()\n",
    "\n",
    "# WITH PARSER - Modified prompt with format instructions\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "prompt_with_parser = PromptTemplate(\n",
    "    template=\"Create a fictional person profile for a {profession}.\\n{format_instructions}\",\n",
    "    input_variables=[\"profession\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "chain_with_parser = prompt_with_parser | model | parser\n",
    "result_with = chain_with_parser.invoke({\"profession\": \"data scientist\"})\n",
    "\n",
    "print(\"AFTER PARSER:\")\n",
    "print(\"Prompt used:\", prompt_with_parser.invoke({\"profession\": \"data scientist\"}))\n",
    "print(f\"Type: {type(result_with)}\")\n",
    "print(f\"result_with: {result_with}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50fdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-crash-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
