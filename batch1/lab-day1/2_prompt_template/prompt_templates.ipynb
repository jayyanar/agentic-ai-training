{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3354f62c",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. <u>Working with String Prompt Templates</u>\n",
    "\n",
    "The most common type of prompt template is the `PromptTemplate`, which is designed to format a prompt from one or more input variables. It's best suited for simpler prompts that can be constructed from a single string.\n",
    "\n",
    "Here is a typical example of how to construct and use a `PromptTemplate`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db3dde4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain about Large Language Models (LLMs) in detail\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Explain about {topic} in detail\")\n",
    "\n",
    "formatted_prompt = prompt_template.invoke({\"topic\": \"Large Language Models (LLMs)\"})\n",
    "print(formatted_prompt.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d2c6c",
   "metadata": {},
   "source": [
    "#### 2. <u>Working with Chat Prompt Templates</u>\n",
    "\n",
    "While `PromptTemplate` is great for single string prompts, chat models work with a list of messages, each having a role (e.g., `System`, `Human`, `AI`). `ChatPromptTemplate` is designed specifically for this purpose.\n",
    "\n",
    "It is built from a list of message templates, allowing you to structure the conversation and provide context to the model. A common pattern involves a `System` message to set the AI's behavior and a `Human` message for the user's query.\n",
    "\n",
    "Here is a common way to construct and use a `ChatPromptTemplate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09b57d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain about Large Language Models (LLMs) in detail', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Explain about {topic} in detail\")\n",
    "])\n",
    "\n",
    "formatted_prompt = prompt_template.invoke({\"topic\": \"Large Language Models (LLMs)\"})\n",
    "print(formatted_prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52af183",
   "metadata": {},
   "source": [
    "#### 3. <u>Using `MessagesPlaceholder` for Chat History</u>\n",
    "\n",
    "While the previous examples use fixed string templates for messages, conversational applications require handling a dynamic list of messages (i.e., the chat history). The `MessagesPlaceholder` is designed for this purpose.\n",
    "\n",
    "It allows you to specify a location in your prompt where a list of messages should be inserted. This is crucial for building chatbots that need to maintain context from previous turns in the conversation.\n",
    "\n",
    "Here is how you can use it to manage chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d32dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that remembers our conversation.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi, my name is Kalyan.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Kalyan! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Create a prompt that includes a placeholder for the chat history\n",
    "prompt_with_history = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that remembers our conversation.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Simulate a past conversation\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Hi, my name is Kalyan.\"),\n",
    "    AIMessage(content=\"Hello Kalyan! It's nice to meet you. How can I help you today?\")\n",
    "]\n",
    "\n",
    "# Format the prompt with the history and a new user input\n",
    "formatted_prompt = prompt_with_history.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What is my name?\"\n",
    "})\n",
    "\n",
    "print(formatted_prompt.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df826ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-crash-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
