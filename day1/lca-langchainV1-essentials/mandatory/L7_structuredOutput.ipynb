{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4aa7046",
      "metadata": {},
      "source": [
        "# Structured Output\n",
        "<img src=\"https://github.com/jayyanar/agentic-ai-training/blob/lab-day-1/batch2/lca-langchainV1-essentials/assets/LC_StructuredOutput.png?raw=1\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b49cb3c-d6c4-4091-b61b-cf9631b29895",
      "metadata": {
        "id": "3b49cb3c-d6c4-4091-b61b-cf9631b29895"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e77dfb-feb2-4872-b815-d751a5270671",
      "metadata": {
        "id": "65e77dfb-feb2-4872-b815-d751a5270671"
      },
      "source": [
        "Load and/or check for needed environmental variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e192158c",
      "metadata": {},
      "source": [
        "What we're doing: Install packages required for the structured-output examples in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ujMCeDqUWCVz",
      "metadata": {
        "id": "ujMCeDqUWCVz"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-groq langgraph langchain-community pysqlite3-binary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7db81c2b",
      "metadata": {},
      "source": [
        "What we're doing: Load the GROQ API key into the environment from Colab userdata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24eb635c-407c-4356-b96a-fe14901a40ea",
      "metadata": {
        "id": "24eb635c-407c-4356-b96a-fe14901a40ea"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b5c8b4b-5326-40fe-9107-f2dec9534d55",
      "metadata": {
        "id": "0b5c8b4b-5326-40fe-9107-f2dec9534d55"
      },
      "source": [
        "## Structured Output Example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1227eec",
      "metadata": {},
      "source": [
        "What we're doing: Initialize the Groq model and define a `TypedDict` response format, then invoke the agent to produce structured output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c74a656-1563-46ce-9719-7897d33d5980",
      "metadata": {
        "id": "1c74a656-1563-46ce-9719-7897d33d5980"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain.agents import create_agent\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize the Groq model\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "class ContactInfo(TypedDict):\n",
        "    name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "    order: str\n",
        "    company: str\n",
        "\n",
        "\n",
        "agent = create_agent(model=llm, response_format=ContactInfo)\n",
        "\n",
        "recorded_conversation = \"\"\"We talked with John Doe. He works over at Example. His number is, let's see,\n",
        "five, five, five, one two three, four, five, six seven. Did you get that?\n",
        "And, his email was john at example.com. He wanted to order 50 boxes of Captain Crunch.\"\"\"\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": recorded_conversation}]}\n",
        ")\n",
        "\n",
        "result[\"structured_response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595fc4e1-bf6d-4a62-8ac8-2f52a921da5e",
      "metadata": {
        "id": "595fc4e1-bf6d-4a62-8ac8-2f52a921da5e"
      },
      "source": [
        "#### Multiple data types are supported"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "627a5354-4713-4951-a710-11698690c117",
      "metadata": {
        "id": "627a5354-4713-4951-a710-11698690c117"
      },
      "source": [
        "* pydantic `BaseModel`\n",
        "* `TypedDict`\n",
        "* `dataclasses`\n",
        "* json schema (dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43922356",
      "metadata": {},
      "source": [
        "What we're doing: Show an alternative structured output using a `pydantic.BaseModel` as the response schema and invoke the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
      "metadata": {
        "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class ContactInfo(BaseModel):\n",
        "    name: str\n",
        "    email: str\n",
        "    phone: str\n",
        "\n",
        "\n",
        "agent = create_agent(model=llm, response_format=ContactInfo)\n",
        "\n",
        "recorded_conversation = \"\"\" We talked with John Doe. He works over at Example. His number is, let's see,\n",
        "five, five, five, one two three, four, five, six seven. Did you get that?\n",
        "And, his email was john at example.com. He wanted to order 50 boxes of Captain Crunch.\"\"\"\n",
        "\n",
        "result = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": recorded_conversation}]}\n",
        ")\n",
        "\n",
        "result[\"structured_response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
      "metadata": {
        "id": "c68179e6-d388-494a-b10d-109c230f6ee0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
