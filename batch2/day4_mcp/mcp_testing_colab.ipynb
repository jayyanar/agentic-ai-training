{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niladridutta1988/wf_agentic_ai_training/blob/main/Batch2/day4_mcp/mcp_testing_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MCP (Model Context Protocol) Testing with LangChain\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Set up MCP servers (Math and Weather)\n",
        "2. Connect to them using different transports (stdio and HTTP)\n",
        "3. Use them with LangChain agents\n",
        "\n",
        "**Author:** Created for testing MCP integration\n",
        "\n",
        "**Date:** January 2026"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "Install all required packages for MCP and LangChain"
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ“¦ Installing dependencies...\")\n",
        "!pip install -q fastmcp mcp langchain langchain-groq langchain-mcp-adapters python-dotenv\n",
        "print(\"âœ… Installation complete!\")"
      ],
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083eb794-a913-4b6c-8947-cdbb6d8a251e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Installing dependencies...\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/6e/78/a850fed8aeef96d4a99043c90b818b2ed5419cd5b24a4049fd7cfb9f1471/fakeredis-2.33.0-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m816.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m416.2/416.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m197.8/197.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.6/119.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m354.2/354.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Set Up API Key\n",
        "\n",
        "**Option 1 (Recommended):** Use Colab Secrets\n",
        "- Click the ğŸ”‘ key icon in the left sidebar\n",
        "- Add new secret: Name = `GROQ_API_KEY`, Value = your API key\n",
        "- Enable \"Notebook access\"\n",
        "\n",
        "**Option 2:** Enter manually when prompted"
      ],
      "metadata": {
        "id": "api_key_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "    print(\"âœ… API key loaded from Colab secrets\")\n",
        "except:\n",
        "    print(\"âš ï¸  No secret found. Enter your API key manually:\")\n",
        "    groq_api_key = input(\"Enter GROQ_API_KEY: \")\n",
        "    os.environ['GROQ_API_KEY'] = groq_api_key\n",
        "    print(\"âœ… API key set\")"
      ],
      "metadata": {
        "id": "api_key",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331d0b5f-c5b9-4f60-9c76-d5a237cf75b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API key loaded from Colab secrets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create Math Server\n",
        "\n",
        "This server provides `add` and `multiply` tools via stdio transport"
      ],
      "metadata": {
        "id": "math_server_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile math_server.py\n",
        "from fastmcp import FastMCP\n",
        "import sys\n",
        "\n",
        "# Ensure unbuffered output for stdio transport\n",
        "sys.stdout.reconfigure(line_buffering=True)\n",
        "sys.stderr.reconfigure(line_buffering=True)\n",
        "\n",
        "mcp = FastMCP(\"Math\")\n",
        "\n",
        "@mcp.tool()\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    print(f\"[Math Server] Adding {a} + {b}\", file=sys.stderr)\n",
        "    return a + b\n",
        "\n",
        "@mcp.tool()\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    print(f\"[Math Server] Multiplying {a} * {b}\", file=sys.stderr)\n",
        "    return a * b\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"[Math Server] Starting...\", file=sys.stderr)\n",
        "    mcp.run(transport=\"stdio\")"
      ],
      "metadata": {
        "id": "math_server",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af259fea-2a75-43ba-d6c1-766e2127b092"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing math_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Create Weather Server\n",
        "\n",
        "This server provides `get_weather` tool via HTTP transport"
      ],
      "metadata": {
        "id": "weather_server_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile weather_server.py\n",
        "from fastmcp import FastMCP\n",
        "\n",
        "mcp = FastMCP(\"Weather\")\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_weather(location: str) -> str:\n",
        "    \"\"\"Get weather for location.\"\"\"\n",
        "    return f\"It's always sunny in {location}!\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting weather server on port 8000...\")\n",
        "    mcp.run(transport=\"streamable-http\", port=8000)"
      ],
      "metadata": {
        "id": "weather_server",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42317e80-39b4-448c-ca97-fc4610c4a897"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weather_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Start Weather Server in Background\n",
        "\n",
        "The weather server runs as an HTTP endpoint"
      ],
      "metadata": {
        "id": "start_weather_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "# Kill any existing server on port 8000\n",
        "!pkill -f weather_server.py 2>/dev/null || true\n",
        "time.sleep(1)\n",
        "\n",
        "# Start weather server in background\n",
        "print(\"ğŸŒ¤ï¸  Starting weather server...\")\n",
        "weather_process = subprocess.Popen(\n",
        "    ['python', 'weather_server.py'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "# Wait for server to start\n",
        "print(\"â³ Waiting for server to start...\")\n",
        "time.sleep(3)\n",
        "\n",
        "# Test if server is running\n",
        "try:\n",
        "    response = requests.get('http://localhost:8000/mcp')\n",
        "    print(f\"âœ… Weather server is running! Status: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Weather server check: {e}\")"
      ],
      "metadata": {
        "id": "start_weather",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40b0b00-d078-4e44-e554-70648c42a335"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "ğŸŒ¤ï¸  Starting weather server...\n",
            "â³ Waiting for server to start...\n",
            "âš ï¸  Weather server check: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /mcp (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f490742db20>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Test Math Server Standalone\n",
        "\n",
        "Test the math server directly using MCP protocol"
      ],
      "metadata": {
        "id": "test_math_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "\n",
        "async def test_math_server():\n",
        "    print(\"ğŸ§® Testing Math Server...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    try:\n",
        "        server_params = StdioServerParameters(\n",
        "            command=\"python\",\n",
        "            args=[\"-u\", \"math_server.py\"],\n",
        "        )\n",
        "\n",
        "        read_stream, write_stream = await stdio_client(server_params)\n",
        "\n",
        "        async with ClientSession(read_stream, write_stream) as session:\n",
        "            await session.initialize()\n",
        "            print(\"âœ“ Server initialized\")\n",
        "\n",
        "            # List tools\n",
        "            tools_result = await session.list_tools()\n",
        "            print(f\"âœ“ Found {len(tools_result.tools)} tools:\")\n",
        "            for tool in tools_result.tools:\n",
        "                print(f\"  - {tool.name}: {tool.description}\")\n",
        "\n",
        "            # Test add\n",
        "            add_result = await session.call_tool(\"add\", {\"a\": 3, \"b\": 5})\n",
        "            print(f\"\\nâœ“ add(3, 5) = {add_result.content[0].text}\")\n",
        "\n",
        "            # Test multiply\n",
        "            multiply_result = await session.call_tool(\"multiply\", {\"a\": 4, \"b\": 6})\n",
        "            print(f\"âœ“ multiply(4, 6) = {multiply_result.content[0].text}\")\n",
        "\n",
        "            print(\"\\nâœ… Math server test passed!\")\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Math server test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# Run the test\n",
        "await test_math_server()"
      ],
      "metadata": {
        "id": "test_math",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e56ade-cbdd-4808-c602-4653995b2da9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§® Testing Math Server...\n",
            "------------------------------------------------------------\n",
            "\n",
            "âŒ Math server test failed: object _AsyncGeneratorContextManager can't be used in 'await' expression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2632049504.py\", line 15, in test_math_server\n",
            "    read_stream, write_stream = await stdio_client(server_params)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: object _AsyncGeneratorContextManager can't be used in 'await' expression\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Test Weather Server Standalone\n",
        "\n",
        "Test the weather server directly using MCP protocol"
      ],
      "metadata": {
        "id": "test_weather_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mcp import ClientSession\n",
        "from mcp.client.sse import sse_client\n",
        "import uuid\n",
        "\n",
        "async def test_weather_server():\n",
        "    print(\"ğŸŒ¤ï¸  Testing Weather Server...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    try:\n",
        "        session_id = str(uuid.uuid4())\n",
        "\n",
        "        async with sse_client(\n",
        "            url=\"http://localhost:8000/mcp\",\n",
        "            headers={\"mcp-session-id\": session_id}\n",
        "        ) as (read_stream, write_stream):\n",
        "\n",
        "            async with ClientSession(read_stream, write_stream) as session:\n",
        "                await session.initialize()\n",
        "                print(\"âœ“ Server initialized\")\n",
        "\n",
        "                # List tools\n",
        "                tools_result = await session.list_tools()\n",
        "                print(f\"âœ“ Found {len(tools_result.tools)} tools:\")\n",
        "                for tool in tools_result.tools:\n",
        "                    print(f\"  - {tool.name}: {tool.description}\")\n",
        "\n",
        "                # Test weather\n",
        "                weather_result = await session.call_tool(\"get_weather\", {\"location\": \"New York\"})\n",
        "                print(f\"\\nâœ“ get_weather('New York') = {weather_result.content[0].text}\")\n",
        "\n",
        "                print(\"\\nâœ… Weather server test passed!\")\n",
        "                return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Weather server test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# Run the test\n",
        "await test_weather_server()"
      ],
      "metadata": {
        "id": "test_weather",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1b0f47-1596-4055-bbd4-16c0ff4f3ad9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸŒ¤ï¸  Testing Weather Server...\n",
            "------------------------------------------------------------\n",
            "\n",
            "âŒ Weather server test failed: unhandled errors in a TaskGroup (1 sub-exception)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  + Exception Group Traceback (most recent call last):\n",
            "  |   File \"/tmp/ipython-input-3085164297.py\", line 12, in test_weather_server\n",
            "  |     async with sse_client(\n",
            "  |                ^^^^^^^^^^^\n",
            "  |   File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
            "  |     return await anext(self.gen)\n",
            "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  |   File \"/usr/local/lib/python3.12/dist-packages/mcp/client/sse.py\", line 63, in sse_client\n",
            "  |     async with anyio.create_task_group() as tg:\n",
            "  |                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  |   File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 783, in __aexit__\n",
            "  |     raise BaseExceptionGroup(\n",
            "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
            "  +-+---------------- 1 ----------------\n",
            "    | Traceback (most recent call last):\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
            "    |     yield\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
            "    |     resp = await self._pool.handle_async_request(req)\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
            "    |     raise exc from None\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
            "    |     response = await connection.handle_async_request(\n",
            "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
            "    |     raise exc\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
            "    |     stream = await self._connect(request)\n",
            "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_async/connection.py\", line 124, in _connect\n",
            "    |     stream = await self._network_backend.connect_tcp(**kwargs)\n",
            "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n",
            "    |     return await self._backend.connect_tcp(\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n",
            "    |     with map_exceptions(exc_map):\n",
            "    |          ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
            "    |     self.gen.throw(value)\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
            "    |     raise to_exc(exc) from exc\n",
            "    | httpcore.ConnectError: All connection attempts failed\n",
            "    | \n",
            "    | The above exception was the direct cause of the following exception:\n",
            "    | \n",
            "    | Traceback (most recent call last):\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/mcp/client/sse.py\", line 69, in sse_client\n",
            "    |     async with aconnect_sse(\n",
            "    |                ^^^^^^^^^^^^^\n",
            "    |   File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
            "    |     return await anext(self.gen)\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx_sse/_api.py\", line 74, in aconnect_sse\n",
            "    |     async with client.stream(method, url, headers=headers, **kwargs) as response:\n",
            "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
            "    |     return await anext(self.gen)\n",
            "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1583, in stream\n",
            "    |     response = await self.send(\n",
            "    |                ^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1629, in send\n",
            "    |     response = await self._send_handling_auth(\n",
            "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
            "    |     response = await self._send_handling_redirects(\n",
            "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
            "    |     response = await self._send_single_request(request)\n",
            "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
            "    |     response = await transport.handle_async_request(request)\n",
            "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
            "    |     with map_httpcore_exceptions():\n",
            "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    |   File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
            "    |     self.gen.throw(value)\n",
            "    |   File \"/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
            "    |     raise mapped_exc(message) from exc\n",
            "    | httpx.ConnectError: All connection attempts failed\n",
            "    +------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Run Full MCP Client with LangChain Agent\n",
        "\n",
        "This combines both servers with a LangChain agent that can use all tools"
      ],
      "metadata": {
        "id": "full_client_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langchain.agents import create_agent\n",
        "from langchain_groq import ChatGroq\n",
        "import sys\n",
        "\n",
        "async def run_mcp_client():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"ğŸš€ MCP CLIENT WITH LANGCHAIN AGENT\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Configure servers\n",
        "    servers = {\n",
        "        \"math\": {\n",
        "            \"transport\": \"stdio\",\n",
        "            \"command\": sys.executable,\n",
        "            \"args\": [\"-u\", \"math_server.py\"],\n",
        "        },\n",
        "        \"weather\": {\n",
        "            \"transport\": \"streamable_http\",\n",
        "            \"url\": \"http://localhost:8000/mcp\",\n",
        "        },\n",
        "    }\n",
        "\n",
        "    print(\"\\nğŸ“‹ Creating MCP client...\")\n",
        "    client = MultiServerMCPClient(servers)\n",
        "\n",
        "    try:\n",
        "        print(\"ğŸ”§ Getting tools...\")\n",
        "        tools = await asyncio.wait_for(client.get_tools(), timeout=15)\n",
        "        print(f\"âœ“ Got {len(tools)} tools:\")\n",
        "        for tool in tools:\n",
        "            print(f\"  - {tool.name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to get tools: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        print(\"\\nğŸ¤– Creating agent...\")\n",
        "        llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0)\n",
        "        agent = create_agent(llm, tools)\n",
        "        print(\"âœ“ Agent created\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed to create agent: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "    # Test 1: Math query\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ§® TEST 1: Math Query\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Question: What's (3 + 5) x 12?\")\n",
        "\n",
        "    try:\n",
        "        math_response = await asyncio.wait_for(\n",
        "            agent.ainvoke({\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 12?\"}]\n",
        "            }),\n",
        "            timeout=30,\n",
        "        )\n",
        "        print(\"\\nğŸ“Š Answer:\")\n",
        "        print(math_response['messages'][-1].content)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Math query failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Test 2: Weather query\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸŒ¤ï¸  TEST 2: Weather Query\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Question: What is the weather in NYC?\")\n",
        "\n",
        "    try:\n",
        "        weather_response = await asyncio.wait_for(\n",
        "            agent.ainvoke({\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in nyc?\"}]\n",
        "            }),\n",
        "            timeout=30,\n",
        "        )\n",
        "        print(\"\\nğŸ“Š Answer:\")\n",
        "        print(weather_response['messages'][-1].content)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Weather query failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Test 3: Combined query\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ”€ TEST 3: Combined Query\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Question: What is 7 times 8, and what's the weather in Paris?\")\n",
        "\n",
        "    try:\n",
        "        combined_response = await asyncio.wait_for(\n",
        "            agent.ainvoke({\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": \"What is 7 times 8, and what's the weather in Paris?\"}]\n",
        "            }),\n",
        "            timeout=30,\n",
        "        )\n",
        "        print(\"\\nğŸ“Š Answer:\")\n",
        "        print(combined_response['messages'][-1].content)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Combined query failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"âœ… ALL TESTS COMPLETE!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "# Run the full client\n",
        "await run_mcp_client()"
      ],
      "metadata": {
        "id": "full_client",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6f3329-1e16-4208-f565-aaa2452fc85e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ğŸš€ MCP CLIENT WITH LANGCHAIN AGENT\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ Creating MCP client...\n",
            "ğŸ”§ Getting tools...\n",
            "âŒ Failed to get tools: fileno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-241423002.py\", line 29, in run_mcp_client\n",
            "    tools = await asyncio.wait_for(client.get_tools(), timeout=15)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_mcp_adapters/client.py\", line 197, in get_tools\n",
            "    tools_list = await asyncio.gather(*load_mcp_tool_tasks)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_mcp_adapters/tools.py\", line 478, in load_mcp_tools\n",
            "    async with create_session(\n",
            "               ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_mcp_adapters/sessions.py\", line 419, in create_session\n",
            "    async with _create_stdio_session(**params) as session:\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_mcp_adapters/sessions.py\", line 231, in _create_stdio_session\n",
            "    stdio_client(server_params) as (read, write),\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/mcp/client/stdio/__init__.py\", line 124, in stdio_client\n",
            "    process = await _create_platform_compatible_process(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/mcp/client/stdio/__init__.py\", line 251, in _create_platform_compatible_process\n",
            "    process = await anyio.open_process(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_core/_subprocesses.py\", line 190, in open_process\n",
            "    return await get_async_backend().open_process(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/anyio/_backends/_asyncio.py\", line 2601, in open_process\n",
            "    process = await asyncio.create_subprocess_exec(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/subprocess.py\", line 224, in create_subprocess_exec\n",
            "    transport, protocol = await loop.subprocess_exec(\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1756, in subprocess_exec\n",
            "    transport = await self._make_subprocess_transport(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/unix_events.py\", line 211, in _make_subprocess_transport\n",
            "    transp = _UnixSubprocessTransport(self, protocol, args, shell,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/base_subprocess.py\", line 36, in __init__\n",
            "    self._start(args=args, shell=shell, stdin=stdin, stdout=stdout,\n",
            "  File \"/usr/lib/python3.12/asyncio/unix_events.py\", line 820, in _start\n",
            "    self._proc = subprocess.Popen(\n",
            "                 ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 992, in __init__\n",
            "    errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/subprocess.py\", line 1745, in _get_handles\n",
            "    errwrite = stderr.fileno()\n",
            "               ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/iostream.py\", line 311, in fileno\n",
            "    raise io.UnsupportedOperation(\"fileno\")\n",
            "io.UnsupportedOperation: fileno\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Cleanup (Optional)\n",
        "\n",
        "Stop the weather server when done"
      ],
      "metadata": {
        "id": "cleanup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ§¹ Cleaning up...\")\n",
        "!pkill -f weather_server.py\n",
        "print(\"âœ… Weather server stopped\")"
      ],
      "metadata": {
        "id": "cleanup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06e2cda-695f-4ada-d6cc-f699488a01ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ Cleaning up...\n",
            "âœ… Weather server stopped\n"
          ]
        }
      ]
    }
  ]
}