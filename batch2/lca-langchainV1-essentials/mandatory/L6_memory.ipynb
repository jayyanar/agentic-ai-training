{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b2cbe59",
      "metadata": {},
      "source": [
        "What we're doing: Install required packages for the memory lesson in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P76ptb0wMCXB",
      "metadata": {
        "id": "P76ptb0wMCXB"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-groq langgraph langchain-community pysqlite3-binary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986af104",
      "metadata": {},
      "source": [
        "What we're doing: Load the GROQ API key from Colab userdata into the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f886dda-3a24-4b1e-baa5-941c74079b52",
      "metadata": {
        "id": "3f886dda-3a24-4b1e-baa5-941c74079b52"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a52fa24c",
      "metadata": {},
      "source": [
        "What we're doing: Connect to the sample SQLite database and print available tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba24dd6-7a31-4fba-8077-2bff96e1ed4a",
      "metadata": {
        "id": "1ba24dd6-7a31-4fba-8077-2bff96e1ed4a"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "db = SQLDatabase.from_uri(\"sqlite:////content/sample_data/Chinook.db\")\n",
        "print(db.get_usable_table_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa4e8dfa",
      "metadata": {},
      "source": [
        "What we're doing: Define `RuntimeContext` dataclass to hold the database reference for runtime use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078cff75-a086-487b-a566-bdb40684d8c3",
      "metadata": {
        "id": "078cff75-a086-487b-a566-bdb40684d8c3"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class RuntimeContext:\n",
        "    db: SQLDatabase"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c8e1e8",
      "metadata": {},
      "source": [
        "What we're doing: Define `execute_sql` tool to allow the agent to run read-only SQL queries via the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d7f0b2c-200a-4246-b547-aff9b5185562",
      "metadata": {
        "id": "5d7f0b2c-200a-4246-b547-aff9b5185562"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langgraph.runtime import get_runtime\n",
        "\n",
        "@tool\n",
        "def execute_sql(query: str) -> str:\n",
        "    \"\"\"Execute a SQLite command and return results.\"\"\"\n",
        "    runtime = get_runtime(RuntimeContext)\n",
        "    db = runtime.context.db\n",
        "\n",
        "    try:\n",
        "        return db.run(query)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "028bf2c7",
      "metadata": {},
      "source": [
        "What we're doing: Set `SYSTEM_PROMPT` rules to constrain agent SQL behavior and ensure read-only queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8f5e3c-d792-434b-9339-3289bbf8398a",
      "metadata": {
        "id": "5d8f5e3c-d792-434b-9339-3289bbf8398a"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a careful SQLite analyst.\n",
        "\n",
        "Rules:\n",
        "- Think step-by-step.\n",
        "- When you need data, call the tool `execute_sql` with ONE SELECT query.\n",
        "- Read-only only; no INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE.\n",
        "- Limit to 5 rows unless the user explicitly asks otherwise.\n",
        "- If the tool returns 'Error:', revise the SQL and try again.\n",
        "- Prefer explicit column lists; avoid SELECT *.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40dbe0d9",
      "metadata": {},
      "source": [
        "What we're doing: Initialize the Groq model and create an agent with `execute_sql` and runtime context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
      "metadata": {
        "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize the Groq model\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "agent = create_agent(\n",
        "    #model=\"openai:gpt-5\",\n",
        "    model=llm,\n",
        "    tools=[execute_sql],\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    context_schema=RuntimeContext,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a79791-1ddc-4fab-aaa7-29a93aa390fb",
      "metadata": {
        "id": "29a79791-1ddc-4fab-aaa7-29a93aa390fb"
      },
      "source": [
        "## Repeated Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3444f220",
      "metadata": {},
      "source": [
        "What we're doing: Stream a repeated query scenario to observe agent behavior without memory enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
      "metadata": {
        "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000"
      },
      "outputs": [],
      "source": [
        "question = \"This is Frank Harris, What was the total on my last invoice?\"\n",
        "steps = []\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\",\n",
        "    context=RuntimeContext(db=db),\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        "    steps.append(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc6b32aa",
      "metadata": {},
      "source": [
        "What we're doing: Follow up query without memory to show that prior context isn't retained across invocations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc965181-609e-470c-a70c-886e6994cfd7",
      "metadata": {
        "id": "fc965181-609e-470c-a70c-886e6994cfd7"
      },
      "outputs": [],
      "source": [
        "question = \"What were the titles?\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede16d8f-0795-4433-9bfc-3295835a0264",
      "metadata": {
        "id": "ede16d8f-0795-4433-9bfc-3295835a0264"
      },
      "source": [
        "## Add memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5011457b",
      "metadata": {},
      "source": [
        "What we're doing: Import an in-memory checkpointer to enable simple agent memory persistence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d07efcc-cade-4a24-9894-9231dadd798e",
      "metadata": {
        "id": "1d07efcc-cade-4a24-9894-9231dadd798e"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import InMemorySaver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa091ca",
      "metadata": {},
      "source": [
        "What we're doing: Re-create the agent with an in-memory checkpointer so it can remember prior interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c9c561-912f-4a53-a8b4-67080c5b6b56",
      "metadata": {
        "id": "66c9c561-912f-4a53-a8b4-67080c5b6b56"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "agent = create_agent(\n",
        "    #model=\"openai:gpt-5\",\n",
        "    model=llm,\n",
        "    tools=[execute_sql],\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    context_schema=RuntimeContext,\n",
        "    checkpointer=InMemorySaver(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4314f5ad",
      "metadata": {},
      "source": [
        "What we're doing: Run the same invoice query with memory enabled (thread_id=1) to persist context between calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6137fd0-fc6a-4410-b939-045ed2cbcb87",
      "metadata": {
        "id": "c6137fd0-fc6a-4410-b939-045ed2cbcb87"
      },
      "outputs": [],
      "source": [
        "question = \"This is Frank Harris, What was the total on my last invoice?\"\n",
        "steps = []\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        "    steps.append(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9086e7b1",
      "metadata": {},
      "source": [
        "What we're doing: Ask a follow-up question using the same memory `thread_id` to check recall of details like titles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
      "metadata": {
        "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6"
      },
      "outputs": [],
      "source": [
        "question = \"What were the titles?\"\n",
        "steps = []\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        "    steps.append(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e94289-66fe-4a30-b351-ea7892302678",
      "metadata": {
        "id": "a3e94289-66fe-4a30-b351-ea7892302678"
      },
      "source": [
        "## Try your own queries\n",
        "Now that there is memory, check the agents recall!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6053ba",
      "metadata": {},
      "source": [
        "What we're doing: Placeholder for you to enter your own question and test agent memory behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2da936e-4528-4fd8-aa80-96f8e66339ef",
      "metadata": {
        "id": "f2da936e-4528-4fd8-aa80-96f8e66339ef"
      },
      "outputs": [],
      "source": [
        "question = \"Your Question Here?\"\n",
        "steps = []\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        "    steps.append(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1270282c",
      "metadata": {},
      "source": [
        "What we're doing: Example follow-up that asks the agent to show full results using the same memory thread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5338bee5-4938-4df8-a7ea-30beb492f33d",
      "metadata": {
        "id": "5338bee5-4938-4df8-a7ea-30beb492f33d"
      },
      "outputs": [],
      "source": [
        "question = \"yes i want to see the full list\"\n",
        "steps = []\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
        "    context=RuntimeContext(db=db),\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()\n",
        "    steps.append(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eecc1744",
      "metadata": {},
      "source": [
        "(End of notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a822e1fa-0466-40aa-aba9-000224528754",
      "metadata": {
        "id": "a822e1fa-0466-40aa-aba9-000224528754"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
