{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 2.3: Human-in-the-Loop - Reviewing Tool Calls\n",
                "\n",
                "In this lab, we will implement a critical safety pattern: review tool calls before they execute. This is common for sensitive actions (e.g., writing to a database, sending emails).\n",
                "\n",
                "## Pattern\n",
                "1. **Agent** decides to call a tool.\n",
                "2. **Interrupt** before the `tools` node.\n",
                "3. **Human** inspects the call.\n",
                "4. **Action**:\n",
                "    - **Approve**: Resume execution.\n",
                "    - **Modify**: Update the tool arguments.\n",
                "    - **Reject**: Cancel and give feedback to the agent."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "%pip install -qU langchain-groq langchain-community langgraph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Setup API Keys\n",
                "import getpass\n",
                "import os\n",
                "\n",
                "if \"GROQ_API_KEY\" not in os.environ:\n",
                "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Define Tools and Agent\n",
                "We create a sensitive tool, e.g., `delete_user`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\Projects\\GenAI Labs\\Jan-2026-day2-labs\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "C:\\Users\\Prathamesh Bonde\\AppData\\Local\\Temp\\ipykernel_16852\\1588312709.py:23: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
                        "  graph = create_react_agent(\n"
                    ]
                }
            ],
            "source": [
                "from langchain_core.tools import tool\n",
                "from langchain_groq import ChatGroq\n",
                "from langgraph.prebuilt import create_react_agent\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "\n",
                "@tool\n",
                "def delete_user(user_id: str):\n",
                "    \"\"\"Deletes a user from the database. Use with caution.\"\"\"\n",
                "    print(f\"!!! DELETING USER {user_id} !!!\")\n",
                "    return f\"User {user_id} deleted successfully.\"\n",
                "\n",
                "# Setup Agent\n",
                "# Initialize LLM\n",
                "llm = ChatGroq(\n",
                "    model=\"qwen/qwen3-32b\",\n",
                "    temperature=0,\n",
                "    reasoning_format=\"parsed\"\n",
                ")\n",
                "memory = MemorySaver()\n",
                "\n",
                "# Create Graph with Interrupt\n",
                "# We interrupt before the 'tools' node executes\n",
                "graph = create_react_agent(\n",
                "    llm, \n",
                "    tools=[delete_user], \n",
                "    checkpointer=memory,\n",
                "    interrupt_before=[\"tools\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Agent (Trigger Tool)\n",
                "We ask the agent to delete a user."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Sending Request ---\n",
                        "--- Execution Paused ---\n"
                    ]
                }
            ],
            "source": [
                "thread_config = {\"configurable\": {\"thread_id\": \"review-demo-1\"}}\n",
                "\n",
                "print(\"--- Sending Request ---\")\n",
                "result = graph.invoke(\n",
                "    {\"messages\": [(\"user\", \"Please delete user 12345\")]}, \n",
                "    config=thread_config\n",
                ")\n",
                "\n",
                "print(\"--- Execution Paused ---\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Inspect Pending Action\n",
                "The graph is paused. Let's see what it wants to do."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pending Tool Calls:\n",
                        "- Tool: delete_user, Args: {'user_id': '12345'}\n"
                    ]
                }
            ],
            "source": [
                "state = graph.get_state(thread_config)\n",
                "last_message = state.values[\"messages\"][-1]\n",
                "\n",
                "# Check if there are tool calls\n",
                "if last_message.tool_calls:\n",
                "    print(\"Pending Tool Calls:\")\n",
                "    for tc in last_message.tool_calls:\n",
                "        print(f\"- Tool: {tc['name']}, Args: {tc['args']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Decision: Approve or Reject\n",
                "Here we can choose to just resume (approve) or update state (reject)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Approving Execution ---\n",
                        "!!! DELETING USER 12345 !!!\n",
                        "Final Response: User 12345 has been deleted from the database. This action is irreversible, so please ensure this was intentional. Let me know if you need further assistance!\n"
                    ]
                }
            ],
            "source": [
                "# APPROVE: Just run invoke(None)\n",
                "# graph.invoke(None, config=thread_config)\n",
                "\n",
                "# REJECT: We can provide feedback by adding a message pretending to be the 'tool output' or just a user message.\n",
                "# A cleaner way often involves using a function to reject, but for simplicity, let's just resume to show it works.\n",
                "\n",
                "print(\"--- Approving Execution ---\")\n",
                "final_result = graph.invoke(None, config=thread_config)\n",
                "\n",
                "print(\"Final Response:\", final_result[\"messages\"][-1].content)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
