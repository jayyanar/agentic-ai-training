{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f11d19b8",
            "metadata": {},
            "source": [
                "# Lab 2.3: Introduction to LangGraph\n",
                "\n",
                "LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain to allow for cycles/loops in your graph.\n",
                "\n",
                "## Key Concepts\n",
                "1. **State**: A shared data structure (usually a TypedDict) that evolves as the graph executes.\n",
                "2. **Nodes**: Functions that accept the current state and return an update to the state.\n",
                "3. **Edges**: Control flow rules (standard or conditional) that determine the next node."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93834b28",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "print(\"Installing dependencies...\")\n",
                "%pip install -qU langchain-groq langchain-community langgraph\n",
                "print(\"Dependencies installed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f33f6c60",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Setup API Keys\n",
                "import getpass\n",
                "import os\n",
                "\n",
                "if \"GROQ_API_KEY\" not in os.environ:\n",
                "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a81f2f1d",
            "metadata": {},
            "source": [
                "## 3. Define the State\n",
                "The state tracks messages in our conversation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "87af9f68",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Annotated\n",
                "from typing_extensions import TypedDict\n",
                "from langgraph.graph.message import add_messages\n",
                "\n",
                "# State definition\n",
                "# We use TypedDict to define the structure of our state.\n",
                "# 'messages' is a list that will store the conversation history.\n",
                "# Annotated[list, add_messages] tells LangGraph that when a node returns a new message,\n",
                "# it should be APPENDED to the existing list (using add_messages), rather than overwriting it.\n",
                "class State(TypedDict):\n",
                "    messages: Annotated[list, add_messages]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2e57dded",
            "metadata": {},
            "source": [
                "## 4. Define Nodes\n",
                "We will creation a simple 'chatbot' node that calls the LLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96d30145",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_groq import ChatGroq\n",
                "from langchain_core.messages import SystemMessage\n",
                "\n",
                "# Initialize the LLM (Large Language Model)\n",
                "# We are using Groq for fast inference.\n",
                "print(\"Initializing LLM...\")\n",
                "llm = ChatGroq(\n",
                "    model=\"qwen/qwen3-32b\",\n",
                "    temperature=0,\n",
                "    reasoning_format=\"parsed\"\n",
                ")\n",
                "print(\"LLM Initialized.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "node_def",
            "metadata": {},
            "outputs": [],
            "source": [
                "def banking_assistant(state: State):\n",
                "    \"\"\"\n",
                "    This function acts as a node in our graph.\n",
                "    It takes the current state as input and returns a dictionary with updates to the state.\n",
                "    \"\"\"\n",
                "    # Enforce banking persona using a SystemMessage\n",
                "    system_message = SystemMessage(content=\"You are a helpful customer service representative for Wells Fargo. You assist customers with their banking inquiries. Be professional and friendly.\")\n",
                "    \n",
                "    # Combine system message with conversation history\n",
                "    messages = [system_message] + state[\"messages\"]\n",
                "    \n",
                "    # Call the LLM and return the result. \n",
                "    # The key 'messages' in the return dictionary matches the key in our State definition.\n",
                "    return {\"messages\": [llm.invoke(messages)]}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "node_test",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's test the component in isolation before building the graph\n",
                "print(\"--- Testing banking_assistant Node ---\")\n",
                "\n",
                "# Create a dummy state with a sample user message\n",
                "from langchain_core.messages import HumanMessage\n",
                "dummy_state = {\"messages\": [HumanMessage(content=\"Hello, can you help me?\")]}\n",
                "\n",
                "# Run the function\n",
                "response = banking_assistant(dummy_state)\n",
                "\n",
                "# Print the output\n",
                "print(\"Node Output:\", response[\"messages\"][-1].content)\n",
                "print(\"----------------------------------------\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c05f9b99",
            "metadata": {},
            "source": [
                "## 5. Build the Graph\n",
                "We use `StateGraph` to wire everything together."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa7a38d0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.graph import StateGraph, START, END\n",
                "\n",
                "# Initialize the graph builder with our State structure\n",
                "graph_builder = StateGraph(State)\n",
                "\n",
                "# Add nodes to the graph\n",
                "# The first argument is the name of the node (string)\n",
                "# The second argument is the function to call\n",
                "graph_builder.add_node(\"banking_assistant\", banking_assistant)\n",
                "\n",
                "# Define the flow (Edges)\n",
                "# START -> banking_assistant -> END\n",
                "graph_builder.add_edge(START, \"banking_assistant\")\n",
                "graph_builder.add_edge(\"banking_assistant\", END)\n",
                "\n",
                "# Compile the graph into a runnable application\n",
                "graph = graph_builder.compile()\n",
                "print(\"Graph compiled successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7061a68e",
            "metadata": {},
            "source": [
                "## 6. Visualization\n",
                "You can visualize the graph structure (requires `graphviz`, optional here)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f26b61d3",
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "\n",
                "try:\n",
                "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
                "except Exception:\n",
                "    # This requires some extra dependencies; ignore if it fails in basic environment\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5aaddc99",
            "metadata": {},
            "source": [
                "## 7. Run the Graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "27d9d690",
            "metadata": {},
            "outputs": [],
            "source": [
                "user_input = \"What are the daily withdrawal limits for a standard checking account?\"\n",
                "\n",
                "# Invoke the graph\n",
                "print(f\"User Input: {user_input}\")\n",
                "print(\"Processing...\")\n",
                "for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
                "    for value in event.values():\n",
                "        print(\"Wells Fargo Assistant:\", value[\"messages\"][-1].content)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}