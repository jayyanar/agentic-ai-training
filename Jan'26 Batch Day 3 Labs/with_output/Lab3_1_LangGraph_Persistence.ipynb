{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "24a6009c",
      "metadata": {
        "id": "24a6009c"
      },
      "source": [
        "# Lab 3.1: LangGraph Persistence (Banking Assistant)\n",
        "\n",
        "In this lab, we will add **Persistence** (Memory) to our graph. This allows the graph to remember the state (e.g., account context) across different interactions, enabling long-running conversations.\n",
        "\n",
        "## Key Concepts\n",
        "1. **Checkpointer**: A mechanism to save the state of the graph at every step.\n",
        "2. **MemorySaver**: An in-memory checkpointer for development/testing.\n",
        "3. **Thread ID**: A unique identifier to separate different user sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c712f929",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c712f929",
        "outputId": "a4241a87-5022-42a6-9e0a-fa4b72bd7f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m157.4/157.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 1. Install Dependencies\n",
        "%pip install -qU langchain-groq langchain-community langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e0d3b1aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0d3b1aa",
        "outputId": "920ab20e-b6d5-443d-ffcf-dd910c9f526c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API Key: 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "# 2. Setup API Keys\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0abd5db",
      "metadata": {
        "id": "a0abd5db"
      },
      "source": [
        "### 3.1 Define State and Imports\n",
        "First, we define the structure of our graph's state and import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f21dab97",
      "metadata": {
        "id": "f21dab97"
      },
      "outputs": [],
      "source": [
        "# Imports and State Definition\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9510fc1a",
      "metadata": {
        "id": "9510fc1a"
      },
      "source": [
        "### 3.2 Initialize LLM and Persona\n",
        "We set up the ChatGroq model and define the system prompt for the Banking Assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0fd9c996",
      "metadata": {
        "id": "0fd9c996"
      },
      "outputs": [],
      "source": [
        "# Initialize LLM\n",
        "llm = ChatGroq(\n",
        "    model=\"qwen/qwen3-32b\",\n",
        "    temperature=0,\n",
        "    reasoning_format=\"parsed\"\n",
        ")\n",
        "\n",
        "# Banking Assistant Persona\n",
        "sys_msg = SystemMessage(content=\"\"\"You are a helpful Wells Fargo banking assistant.\n",
        "You can answer questions about account balances and transactions.\n",
        "- If the user asks about a balance or transactions, ALWAYS check if they have specified the account type (Checking or Savings).\n",
        "- If they haven't specified, ask them \"Which account?\".\n",
        "- If they have specified (or it's clear from conversation history), provide a mock answer.\n",
        "    - Checking Balance: $2,500\n",
        "    - Savings Balance: $10,500\n",
        "    - Checking Transactions: Walmart (-$50), Deposit (+$1000)\n",
        "    - Savings Transactions: Interest (+$50)\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f5becd",
      "metadata": {
        "id": "10f5becd"
      },
      "source": [
        "### 3.3 Define Node Function\n",
        "Here we define the chatbot node. We add a print statement to see when this node is actually executed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "838af182",
      "metadata": {
        "id": "838af182"
      },
      "outputs": [],
      "source": [
        "def chatbot(state: State):\n",
        "    print(\"--- Node: Chatbot Activated ---\")\n",
        "    return {\"messages\": [llm.invoke([sys_msg] + state[\"messages\"])]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d1e034f",
      "metadata": {
        "id": "5d1e034f"
      },
      "source": [
        "### 3.4 Verification: Test the Chatbot Node\n",
        "Before building the graph, let's test the `chatbot` function directly to ensure it responds correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4cf9d7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4cf9d7a",
        "outputId": "eab74028-dbea-47a6-a996-8bb14f3250da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running verification...\n",
            "--- Node: Chatbot Activated ---\n",
            "Response: Hello! I can help you check your account balances, view recent transactions, and provide details about your Checking or Savings accounts. For example, you can ask:  \n",
            "- \"What's my Checking balance?\"  \n",
            "- \"Show my Savings transactions.\"  \n",
            "Let me know how I can assist! \n"
          ]
        }
      ],
      "source": [
        "# Verification: Test the node directly\n",
        "print(\"Running verification...\")\n",
        "dummy_state = {\"messages\": [(\"user\", \"Hello, what can you do?\")]}\n",
        "response = chatbot(dummy_state)\n",
        "print(\"Response:\", response['messages'][0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c62a83",
      "metadata": {
        "id": "57c62a83"
      },
      "source": [
        "### 3.5 Build the Graph\n",
        "Now we assemble the nodes and edges into a `StateGraph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db1d1c30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db1d1c30",
        "outputId": "0a4fbbdd-e847-465b-e7f4-aaa7356f9e63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d4bc677c7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b06fba1",
      "metadata": {
        "id": "0b06fba1"
      },
      "source": [
        "## 4. Add Persistence\n",
        "We use `MemorySaver` to store the state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c1b7d543",
      "metadata": {
        "id": "c1b7d543"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile with checkpointer\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e843d1c",
      "metadata": {
        "id": "1e843d1c"
      },
      "source": [
        "## 5. Run with Thread ID\n",
        "We use `configurable` to specify the thread. In this initial interaction, we establish the context (Checking Account)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2ee901cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ee901cc",
        "outputId": "7a070444-9f04-4879-f65f-18c6e0e3af37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Node: Chatbot Activated ---\n",
            "Assistant: Your **Checking account** balance is **$2,500**.  \n",
            "\n",
            "**Recent transactions:**  \n",
            "- Walmart: -$50  \n",
            "- Deposit: +$1,000  \n",
            "\n",
            "Let me know if you'd like more details or assistance! \n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# User establishes context\n",
        "user_input = \"I have a question about my Checking account.\"\n",
        "\n",
        "for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config=config):\n",
        "    for value in event.values():\n",
        "        print(\"Assistant:\", value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1398e57d",
      "metadata": {
        "id": "1398e57d"
      },
      "source": [
        "## 6. Verify Memory (Persistence)\n",
        "Now we ask \"What is the balance?\" **without specifying the account**. The bot should remember we are talking about **Checking** because of the shared `thread_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "408885b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "408885b2",
        "outputId": "eab063f4-eae0-4bcd-c4de-35d8df408dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Node: Chatbot Activated ---\n",
            "Assistant: Your **Checking account** balance is **$2,500**.  \n",
            "\n",
            "**Recent activity:**  \n",
            "- Walmart: -$50  \n",
            "- Deposit: +$1,000  \n",
            "\n",
            "Let me know if you need further assistance! \n"
          ]
        }
      ],
      "source": [
        "user_input = \"What is the balance?\"\n",
        "\n",
        "# Note: We are using the same 'config' with thread_id='1'\n",
        "for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config=config):\n",
        "    for value in event.values():\n",
        "        print(\"Assistant:\", value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb74afe",
      "metadata": {
        "id": "ffb74afe"
      },
      "source": [
        "## 7. New Thread (No Memory)\n",
        "If we change the `thread_id` to \"2\", the memory should be empty. The bot should NOT know which account we are referring to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6b9cdfbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b9cdfbe",
        "outputId": "0c6b25a4-5063-43ed-a0b2-8390a79ffc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Node: Chatbot Activated ---\n",
            "Assistant: Which account?\n"
          ]
        }
      ],
      "source": [
        "config_new = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "# Asking the same question in a new thread\n",
        "user_input = \"What is the balance?\"\n",
        "\n",
        "for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config=config_new):\n",
        "    for value in event.values():\n",
        "        print(\"Assistant:\", value[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f0bc18b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0bc18b4",
        "outputId": "c609267d-ad3f-4d5b-9b03-b3864f12efa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Node: Chatbot Activated ---\n",
            "Assistant: Your **Savings Account Balance** is **$10,500**.  \n",
            "\n",
            "**Recent Savings Transactions:**  \n",
            "- Interest: +$50  \n",
            "\n",
            "Let me know if you need further details! \n"
          ]
        }
      ],
      "source": [
        "user_input = \"For the Savings account.\"\n",
        "\n",
        "# Note: We are using the same 'config' with thread_id='1'\n",
        "for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config=config_new):\n",
        "    for value in event.values():\n",
        "        print(\"Assistant:\", value[\"messages\"][-1].content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}